{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GZVfdZMw3B4Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchmetrics.functional import accuracy\n",
        "from src.utils.common import Accumulator\n",
        "\n",
        "\n",
        "def topIndices(vec, x, largest):\n",
        "    sorted_idx = torch.argsort(vec, descending=largest)\n",
        "    top_x_idxs, other_idxs = (sorted_idx[:x], sorted_idx[x:])\n",
        "    return top_x_idxs, other_idxs\n",
        "\n",
        "def irreducibleLoss(data=None, target=None, global_index=None, \n",
        "                              irreducible_loss_model=None, target_device=None):\n",
        "    \n",
        "    if type(irreducible_loss_model) is torch.Tensor:\n",
        "        if (target_device is not None and irreducible_loss_model.device != target_device ):\n",
        "            irreducible_loss_model = irreducible_loss_model.to(device=target_device)\n",
        "        irreducible_loss = irreducible_loss_model[global_index]\n",
        "    else:\n",
        "        irreducible_loss = F.cross_entropy(irreducible_loss_model(data), target, reduction=\"none\")\n",
        "    return irreducible_loss\n",
        "\n",
        "class ReducibleLossSelection:\n",
        "    bald = False\n",
        "\n",
        "    def __call__(self, selected_batch_size, data=None, target=None, global_index=None, large_model=None,\n",
        "        irreducible_loss_model=None):\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            model_loss = F.cross_entropy( large_model(data), target, reduction=\"none\")\n",
        "\n",
        "            irreducible_loss = irreducibleLoss(data, target, global_index, irreducible_loss_model, model_loss.device)\n",
        "\n",
        "            reducible_loss = model_loss - irreducible_loss\n",
        "\n",
        "            top_x_idxs, _ = topIndices( reducible_loss, selected_batch_size, largest=True )\n",
        "            selected_irreducible_loss = irreducible_loss[top_x_idxs]\n",
        "\n",
        "        return top_x_idxs, selected_irreducible_loss\n",
        "    \n",
        "selection_method = ReducibleLossSelection()\n",
        "update_irreducible = True\n",
        "\n",
        "def train_irr_loss(\n",
        "        irreducible_loss_clf, \n",
        "        data_loader,\n",
        "        loss_fn, \n",
        "        opt, \n",
        "        accumulator : Accumulator = None , \n",
        "        selection__mode = True, presample = 3.0 ):\n",
        "    \n",
        "    # BEGIN Solution (do not delete this comment!)\n",
        "    ret_loss, correct = (0.0, 0)\n",
        "    irreducible_loss_clf.train(True)  # Set model to training mode\n",
        "    \n",
        "    for x, labels in data_loader:\n",
        "        x, labels = x.cuda(), labels.cuda()\n",
        "        opt.zero_grad()\n",
        "        all_pred = irreducible_loss_clf(x)\n",
        "        loss = loss_fn(all_pred, labels).mean()\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        ret_loss += loss.item()\n",
        "        #pred = all_pred.max(1)[1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #correct += (pred==labels).sum().item()\n",
        "            correct += (all_pred.argmax(dim=1) == labels).sum().cpu().item()\n",
        "\n",
        "    ret_loss = ret_loss / len(data_loader)\n",
        "    accuracy = correct / len(data_loader.dataset)\n",
        "\n",
        "\n",
        "    return {\"ret_loss\":ret_loss, \"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "def train_batch_rho_loss(\n",
        "        large_model,\n",
        "        irreducible_loss_model,\n",
        "        batch,\n",
        "        loss_fn, \n",
        "        optimizer, \n",
        "        accumulator : Accumulator, \n",
        "        selection__mode = True, presample = 3.0 ):\n",
        "\n",
        "\n",
        "    global_index, data, target = batch\n",
        "    batch_size = len(data)\n",
        "    selected_batch_size = max(1, int(batch_size /presample))\n",
        "\n",
        "\n",
        "    large_model.eval() \n",
        "\n",
        "    selected_indices,  irreducible_loss = selection_method.__call__(\n",
        "        selected_batch_size=selected_batch_size,\n",
        "        data=data,\n",
        "        target=target,\n",
        "        global_index=global_index,\n",
        "        large_model=large_model,\n",
        "        irreducible_loss_model=irreducible_loss_model,\n",
        "    ) \n",
        "\n",
        "    large_model.train()  # switch to eval mode to compute selection\n",
        "\n",
        "    data, target = data[selected_indices], target[selected_indices]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = large_model(data)\n",
        "    loss = loss_fn(logits, target) \n",
        "\n",
        "    mean_loss = loss.mean()\n",
        "    mean_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # training metrics\n",
        "    #preds = torch.argmax(F.log_softmax(logits, dim=1), dim=1)\n",
        "\n",
        "    n = len(logits)\n",
        "    acc = (logits.argmax(dim=1) == target).sum().cpu().item()/n\n",
        "\n",
        "    accumulator.average( \n",
        "        train_loss = ( mean_loss.cpu().item(), n) ,\n",
        "        train_acc = ( acc, n) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def train_full( model, model_irr, train_dataloader, train_irr_loader, loss_fn, optimizer,optimizer_irr,\n",
        "                n_epochs, eval = None, callback=None, presample=3, tau_th = None):\n",
        "    #model_irr = copy.deepcopy(model)\n",
        "\n",
        "\n",
        "    large_batch = int( train_dataloader.batch_size)\n",
        "    \n",
        "    if callback :\n",
        "        callback.setMeta(\n",
        "            large_batch = large_batch,\n",
        "            n_epochs = n_epochs, \n",
        "            presample = presample, \n",
        "            tau_th = tau_th)\n",
        "        \n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(\"irr_model\"))\n",
        "        model.eval()\n",
        "        print(\"irr model loades\")\n",
        "    except:\n",
        "        epochs = tqdm(range(n_epochs), desc='Irr epochs', leave=True)\n",
        "        for i_epoch in epochs:\n",
        "            dict_ = train_irr_loss(model_irr, train_irr_loader, loss_fn, optimizer_irr)\n",
        "            epochs.set_postfix(dict_)\n",
        "\n",
        "    torch.save(model_irr.state_dict(), \"irr_model\")\n",
        "    \n",
        "    d = model.device\n",
        "    epochs = tqdm(range(n_epochs), desc='Epochs', leave=True)\n",
        "    for i_epoch in epochs:\n",
        "        accum = Accumulator()\n",
        "        \n",
        "        \n",
        "        for idxs, X_batch, y_batch in train_dataloader:\n",
        "            train_batch_rho_loss(model, \n",
        "                                model_irr,\n",
        "                                (idxs, X_batch.to(d), y_batch.to(d)),\n",
        "                                loss_fn,\n",
        "                                optimizer, \n",
        "                                accum,\n",
        "                                presample)\n",
        "\n",
        "        if callback :\n",
        "            val_scores = eval(model) if eval else {}\n",
        "            cb_dict = callback( **accum.getAll(), **val_scores)\n",
        "            epochs.set_postfix(cb_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lIoX388SbM2B"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    logits = []\n",
        "    targets = []\n",
        "    with torch.no_grad():\n",
        "        for  X_batch, y_batch in dataloader:\n",
        "            output = model(X_batch.to(model.device)).cpu()\n",
        "            logits.append(output)\n",
        "            targets.append(y_batch)\n",
        "    logits = torch.cat(logits)\n",
        "    targets = torch.cat(targets)\n",
        "    loss = loss_fn(logits, targets).mean().item()\n",
        "    acc = (logits.argmax(dim=1) == targets).sum().item() / len(targets)\n",
        "    return loss, acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b2a082ng909",
        "outputId": "95bb5ec9-c5e5-499c-a320-6a73ee1f28cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from src.utils.data_loaders import train_dataloader, test_dataloader, train_val_dataloader\n",
        "\n",
        "train_irr_loader  = train_dataloader(batch_size=120, subset=0.25)#128*3\n",
        "train_loader, test_loader = train_val_dataloader(batch_size=120, index=True)\n",
        "#test_loader = test_dataloader(batch_size=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "%aimport common_utils\n",
        "%autoreload 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "140f36be62884c6599ebbeb158c510fb",
            "deb6e2113cc447b086689fcbdad52c04",
            "b82a70b6df324aeaab2a9eb75bf85644",
            "200602909c07477cbcb532a0d65d5432",
            "334914dcb0c9465fa5d60661731228d4",
            "42960e386be646aebc002e0568c76564",
            "8b7e55b7f8fc42d589f1e65ab0cb5595",
            "cfebb3f379e44337a62adbc059dbe9ee",
            "ab493f44ff394bebb85e98de872d0f0d",
            "de9a1672a6fd47049e807687982874b9",
            "3caddfc99f464c39ae5cab28c6afb89a"
          ]
        },
        "id": "CYibWIl3fk3V",
        "outputId": "a0d3278b-d019-481a-d379-a8287955aeea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "irr model loades\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   0%|          | 0/50 [02:20<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 33\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#print(len(train_loader))\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print(len(test_loader))\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print(len(train_irr_loader))\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mtrain_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmodel_irr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m           \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m           \u001b[49m\u001b[43mtrain_irr_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m           \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m           \u001b[49m\u001b[43moptimizer_irr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m           \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m           \u001b[49m\u001b[43mpresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m           \u001b[49m\u001b[43mtau_th\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m callback\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrho_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[9], line 46\u001b[0m, in \u001b[0;36mtrain_full\u001b[1;34m(model, model_irr, train_dataloader, train_irr_loader, loss_fn, optimizer, optimizer_irr, n_epochs, eval, callback, presample, tau_th)\u001b[0m\n\u001b[0;32m     37\u001b[0m     train_batch_rho_loss(model, \n\u001b[0;32m     38\u001b[0m                         model_irr,\n\u001b[0;32m     39\u001b[0m                         (idxs, X_batch\u001b[38;5;241m.\u001b[39mto(d), y_batch\u001b[38;5;241m.\u001b[39mto(d)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m                         accum,\n\u001b[0;32m     43\u001b[0m                         presample)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback :\n\u001b[1;32m---> 46\u001b[0m     val_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28meval\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m     47\u001b[0m     cb_dict \u001b[38;5;241m=\u001b[39m callback( \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maccum\u001b[38;5;241m.\u001b[39mgetAll(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mval_scores)\n\u001b[0;32m     48\u001b[0m     epochs\u001b[38;5;241m.\u001b[39mset_postfix(cb_dict)\n",
            "Cell \u001b[1;32mIn[28], line 26\u001b[0m, in \u001b[0;36meval_callback\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_callback\u001b[39m(model):\n\u001b[1;32m---> 26\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc}\n",
            "Cell \u001b[1;32mIn[25], line 6\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataloader, loss_fn)\u001b[0m\n\u001b[0;32m      4\u001b[0m targets \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      7\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(X_batch\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice))\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m      8\u001b[0m         logits\u001b[38;5;241m.\u001b[39mappend(output)\n",
            "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ],
      "source": [
        "%autoreload 1\n",
        "from src.models import ResNet50\n",
        "from src.utils.common import UnCallBack\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "\n",
        "model = ResNet50()\n",
        "model.to(device)\n",
        "model.device = device\n",
        "\n",
        "model_irr = ResNet50()\n",
        "model_irr.to(device)\n",
        "model_irr.device = device\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 )\n",
        "optimizer_irr = torch.optim.Adam(model_irr.parameters(), lr = 1e-3 )\n",
        "\n",
        "callback = UnCallBack( info_list = ['train_loss', 'train_acc', 'train_w_loss', 'val_loss', 'val_acc', 'train_uniform_cnt'])\n",
        "\n",
        "def eval_callback(model):\n",
        "    loss, acc =evaluate(model, test_loader, loss_fn)\n",
        "    return {\"val_loss\": loss, \"val_acc\": acc}\n",
        "\n",
        "#print(len(train_loader))\n",
        "#print(len(test_loader))\n",
        "#print(len(train_irr_loader))\n",
        "\n",
        "train_full(model, \n",
        "           model_irr,\n",
        "           train_loader, \n",
        "           train_irr_loader,\n",
        "           loss_fn, \n",
        "           optimizer, \n",
        "           optimizer_irr,\n",
        "           n_epochs=50, \n",
        "           eval=eval_callback, \n",
        "           callback=callback, \n",
        "           presample=3, \n",
        "           tau_th = None)\n",
        "\n",
        "callback.save(\"rho_loss\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "140f36be62884c6599ebbeb158c510fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_deb6e2113cc447b086689fcbdad52c04",
              "IPY_MODEL_b82a70b6df324aeaab2a9eb75bf85644",
              "IPY_MODEL_200602909c07477cbcb532a0d65d5432"
            ],
            "layout": "IPY_MODEL_334914dcb0c9465fa5d60661731228d4"
          }
        },
        "200602909c07477cbcb532a0d65d5432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9a1672a6fd47049e807687982874b9",
            "placeholder": "​",
            "style": "IPY_MODEL_3caddfc99f464c39ae5cab28c6afb89a",
            "value": " 1/30 [02:35&lt;1:15:13, 155.64s/it, loss_train=2.093855035463969, acc_train=0.26826666666666665, w_loss_train=2.093669682184855, loss_val=2.4236364364624023, acc_val=0.3442]"
          }
        },
        "334914dcb0c9465fa5d60661731228d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3caddfc99f464c39ae5cab28c6afb89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42960e386be646aebc002e0568c76564": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7e55b7f8fc42d589f1e65ab0cb5595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab493f44ff394bebb85e98de872d0f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b82a70b6df324aeaab2a9eb75bf85644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfebb3f379e44337a62adbc059dbe9ee",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab493f44ff394bebb85e98de872d0f0d",
            "value": 1
          }
        },
        "cfebb3f379e44337a62adbc059dbe9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9a1672a6fd47049e807687982874b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb6e2113cc447b086689fcbdad52c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42960e386be646aebc002e0568c76564",
            "placeholder": "​",
            "style": "IPY_MODEL_8b7e55b7f8fc42d589f1e65ab0cb5595",
            "value": "Epochs:   3%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
