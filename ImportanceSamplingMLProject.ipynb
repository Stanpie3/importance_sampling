{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "140f36be62884c6599ebbeb158c510fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_deb6e2113cc447b086689fcbdad52c04",
              "IPY_MODEL_b82a70b6df324aeaab2a9eb75bf85644",
              "IPY_MODEL_200602909c07477cbcb532a0d65d5432"
            ],
            "layout": "IPY_MODEL_334914dcb0c9465fa5d60661731228d4"
          }
        },
        "deb6e2113cc447b086689fcbdad52c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42960e386be646aebc002e0568c76564",
            "placeholder": "​",
            "style": "IPY_MODEL_8b7e55b7f8fc42d589f1e65ab0cb5595",
            "value": "Epochs:   3%"
          }
        },
        "b82a70b6df324aeaab2a9eb75bf85644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfebb3f379e44337a62adbc059dbe9ee",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab493f44ff394bebb85e98de872d0f0d",
            "value": 1
          }
        },
        "200602909c07477cbcb532a0d65d5432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9a1672a6fd47049e807687982874b9",
            "placeholder": "​",
            "style": "IPY_MODEL_3caddfc99f464c39ae5cab28c6afb89a",
            "value": " 1/30 [02:35&lt;1:15:13, 155.64s/it, loss_train=2.093855035463969, acc_train=0.26826666666666665, w_loss_train=2.093669682184855, loss_val=2.4236364364624023, acc_val=0.3442]"
          }
        },
        "334914dcb0c9465fa5d60661731228d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42960e386be646aebc002e0568c76564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7e55b7f8fc42d589f1e65ab0cb5595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfebb3f379e44337a62adbc059dbe9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab493f44ff394bebb85e98de872d0f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de9a1672a6fd47049e807687982874b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3caddfc99f464c39ae5cab28c6afb89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG-zLv7wiXS4",
        "outputId": "13929880-b1ff-4df4-f3c9-af066c61dd02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/importance-sampling')"
      ],
      "metadata": {
        "id": "ulqHQtCEW2CF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXFBQv5ZXd8L",
        "outputId": "f2a0edd9-1a04-479f-eb6f-4664d8d312b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10, MNIST, CIFAR100\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from torchmetrics.functional import accuracy\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "GZVfdZMw3B4Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(\n",
        "    mean=[0.4914, 0.4822, 0.4465],\n",
        "    std=[0.247, 0.2435, 0.2616],\n",
        ")\n",
        "\n",
        "def samplers(n, split_shuffle=True, val_size=0.1):\n",
        "    if split_shuffle:\n",
        "        idx = torch.randperm(n, generator=torch.Generator().manual_seed(0))\n",
        "    else:\n",
        "        idx = torch.arange(n)\n",
        "    split_idx = int((1.0 - val_size) * n)\n",
        "    train_sampler = SubsetRandomSampler(idx[:split_idx])\n",
        "    val_sampler = SubsetRandomSampler(idx[split_idx:])\n",
        "    return train_sampler, val_sampler\n",
        "\n",
        "def train_val_dataloader(root_dir='./cifar10', split_shuffle=True, val_size=0.1, batch_size=120):\n",
        "    train_dataset = CIFAR10(root=root_dir, train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
        "    val_dataset = CIFAR10(root=root_dir, train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
        "\n",
        "\n",
        "    train_sampler, val_sampler = samplers(len(train_dataset), split_shuffle, val_size)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=int(batch_size / 3))\n",
        "    return train_dataloader, val_dataloader\n",
        "\n",
        "def test_dataloader(root_dir='./cifar10', batch_size=120):\n",
        "    test_dataset = CIFAR10(root=root_dir, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "    return test_dataloader"
      ],
      "metadata": {
        "id": "_N4i8iV5J6T3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(model, x_batch, y_batch, loss_fn, optimizer, presample=3.0):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    batch_size = x_batch.shape[0]\n",
        "    selected_batch_size = int(batch_size / presample)\n",
        "    output = model(x_batch)\n",
        "    num_classes = output.shape[1]\n",
        "    with torch.no_grad():\n",
        "        probs = F.softmax(output, dim=1)\n",
        "        one_hot_targets = F.one_hot(y_batch, num_classes=num_classes)\n",
        "        g_i_norm = torch.norm(probs - one_hot_targets, dim=-1).detach().cpu().numpy()\n",
        "    p_i = g_i_norm / np.sum(g_i_norm)\n",
        "    batch_indices = np.random.choice(np.arange(batch_size), size=selected_batch_size, replace=True, p=p_i)\n",
        "    selected_p_i = p_i[batch_indices]\n",
        "    loss = loss_fn(output, y_batch)\n",
        "    selected_loss = loss[batch_indices]\n",
        "    w_i = 1.0 / (batch_size * selected_p_i)\n",
        "    weighted_loss = (torch.tensor(w_i).to(selected_loss.device).detach() * selected_loss).mean()\n",
        "    weighted_loss.backward()\n",
        "    optimizer.step()\n",
        "    batch_loss = loss.mean().cpu().item()\n",
        "    weighted_batch_loss = weighted_loss.mean().cpu().item()\n",
        "    max_p_i = np.max(p_i)\n",
        "    num_unique_points = np.unique(batch_indices).size\n",
        "    with torch.no_grad():\n",
        "        batch_acc_sum = (output.argmax(dim=1) == y_batch).sum().cpu().item()\n",
        "    return batch_loss, batch_acc_sum, weighted_batch_loss, max_p_i, num_unique_points, selected_batch_size"
      ],
      "metadata": {
        "id": "XKWRwU7F32-S"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, loss_fn, optimizer):\n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0\n",
        "    epoch_weighted_loss = 0.0\n",
        "    epoch_max_p_i_s = []\n",
        "    epoch_num_unique_points_s = []\n",
        "    epoch_size = 0\n",
        "    epoch_weighted_size = 0\n",
        "    for i_batch, (X_batch, y_batch) in enumerate(dataloader):\n",
        "        batch_loss, batch_acc_sum, weighted_batch_loss, max_p_i, num_unique_points, selected_batch_size = train_batch(model, X_batch.to(model.device), y_batch.to(model.device), loss_fn, optimizer)\n",
        "        epoch_size += len(X_batch)\n",
        "        epoch_weighted_size += selected_batch_size\n",
        "        epoch_loss += batch_loss * len(X_batch)\n",
        "        epoch_acc += batch_acc_sum\n",
        "        epoch_weighted_loss += weighted_batch_loss * selected_batch_size\n",
        "        epoch_max_p_i_s.append(max_p_i)\n",
        "        epoch_num_unique_points_s.append(num_unique_points)\n",
        "    epoch_loss /= epoch_size\n",
        "    epoch_acc /= epoch_size\n",
        "    epoch_weighted_loss /= epoch_weighted_size\n",
        "    return epoch_loss, epoch_acc, epoch_weighted_loss, epoch_max_p_i_s, epoch_num_unique_points_s\n"
      ],
      "metadata": {
        "id": "pxY0TU4lyorv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_full(model, train_dataloader, val_dataloader, loss_fn, optimizer, n_epochs, callback=None):\n",
        "    epochs = tqdm(range(n_epochs), desc='Epochs', leave=True)\n",
        "    for i_epoch in epochs:\n",
        "        epoch_loss, epoch_acc, epoch_weighted_loss, epoch_max_p_i_s, epoch_num_unique_points_s = train_epoch(model, train_dataloader, loss_fn, optimizer)\n",
        "        if callback is not None:\n",
        "            cb_dict = callback(model, val_dataloader, loss_fn, epoch_loss, epoch_acc, epoch_weighted_loss, epoch_max_p_i_s, epoch_num_unique_points_s)\n",
        "            epochs.set_postfix(cb_dict)\n",
        "\n"
      ],
      "metadata": {
        "id": "f-oBZz0aWgcG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CallBack:\n",
        "    def __init__(self, eval_fn, name=None):\n",
        "        self.eval_fn = eval_fn\n",
        "        self.train_losses = []\n",
        "        self.train_accs = []\n",
        "        self.train_w_losses = []\n",
        "        self.train_max_p_i = []\n",
        "        self.train_num_unique_points = []\n",
        "        self.val_losses = []\n",
        "        self.val_accs = []\n",
        "\n",
        "    def last_info(self):\n",
        "        return {'loss_train': f'{self.train_losses[-1]}',\n",
        "                'acc_train': f'{self.train_accs[-1]}',\n",
        "                'w_loss_train': f'{self.train_w_losses[-1]}',\n",
        "                'loss_val': f'{self.val_losses[-1]}',\n",
        "                'acc_val': f'{self.val_accs[-1]}',\n",
        "        }\n",
        "    def __call__(self, model, val_dataloader, loss_fn,\n",
        "                 epoch_loss=None, epoch_acc=None, epoch_weighted_loss=None, epoch_max_p_i_s=None, epoch_num_unique_points_s=None):\n",
        "        self.train_losses.append(epoch_loss)\n",
        "        self.train_accs.append(epoch_acc)\n",
        "        self.train_w_losses.append(epoch_weighted_loss)\n",
        "        self.train_max_p_i.append(epoch_max_p_i_s)\n",
        "        self.train_num_unique_points.append(epoch_num_unique_points_s)\n",
        "        loss_val, acc_val = self.eval_fn(model, val_dataloader, loss_fn)\n",
        "        self.val_losses.append(loss_val)\n",
        "        self.val_accs.append(acc_val)\n",
        "        return self.last_info()\n"
      ],
      "metadata": {
        "id": "H4zSEp-ZY1Yw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    logits = []\n",
        "    targets = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            output = model(X_batch.to(model.device)).cpu()\n",
        "            logits.append(output)\n",
        "            targets.append(y_batch)\n",
        "    logits = torch.cat(logits)\n",
        "    targets = torch.cat(targets)\n",
        "    loss = loss_fn(logits, targets).mean().item()\n",
        "    acc = (logits.argmax(dim=1) == targets).sum().item() / len(targets)\n",
        "    return loss, acc\n",
        "\n"
      ],
      "metadata": {
        "id": "lIoX388SbM2B"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####ResNet\n",
        "#class BasicBlock(nn.Module):\n",
        "#    expansion = 1\n",
        "\n",
        "#    def __init__(self, in_planes, planes, stride=1):\n",
        "#        super(BasicBlock, self).__init__()\n",
        "#        self.activation = F.relu\n",
        "#        self.conv1 = nn.Conv2d(\n",
        "#            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#        self.bn1 = nn.BatchNorm2d(planes)\n",
        "#        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "#                               stride=1, padding=1, bias=False)\n",
        "#        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "#        self.shortcut = nn.Sequential()\n",
        "#        if stride != 1 or in_planes != self.expansion*planes:\n",
        "#            self.shortcut = nn.Sequential(\n",
        "#                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "#                          kernel_size=1, stride=stride, bias=False),\n",
        "#                nn.BatchNorm2d(self.expansion*planes)\n",
        "#            )\n",
        "\n",
        "#    def forward(self, x):\n",
        "#        out = self.activation(self.bn1(self.conv1(x)))\n",
        "#        out = self.bn2(self.conv2(out))\n",
        "#        out += self.shortcut(x)\n",
        "#        out = self.activation(out)\n",
        "#        return out\n",
        "\n",
        "\n",
        "#class Bottleneck(nn.Module):\n",
        "#    expansion = 4\n",
        "\n",
        "#    def __init__(self, in_planes, planes, stride=1):\n",
        "#        super(Bottleneck, self).__init__()\n",
        "#        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "#        self.bn1 = nn.BatchNorm2d(planes)\n",
        "#        self.conv2 = nn.Conv2d(\n",
        "#            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "#        )\n",
        "#        self.bn2 = nn.BatchNorm2d(planes)\n",
        "#        self.conv3 = nn.Conv2d(\n",
        "#            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "#        )\n",
        "#        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "#        self.shortcut = nn.Sequential()\n",
        "#        if stride != 1 or in_planes != self.expansion * planes:\n",
        "#            self.shortcut = nn.Sequential(\n",
        "#                nn.Conv2d(\n",
        "#                    in_planes,\n",
        "#                    self.expansion * planes,\n",
        "#                    kernel_size=1,\n",
        "#                    stride=stride,\n",
        "#                    bias=False,\n",
        "#                ),\n",
        "#                nn.BatchNorm2d(self.expansion * planes),\n",
        "#            )\n",
        "\n",
        "#    def forward(self, x):\n",
        "#        out = F.relu(self.bn1(self.conv1(x)))\n",
        "#        out = F.relu(self.bn2(self.conv2(out)))\n",
        "#        out = self.bn3(self.conv3(out))\n",
        "#        out += self.shortcut(x)\n",
        "#        out = F.relu(out)\n",
        "#        return out"
      ],
      "metadata": {
        "id": "RUtiAR0Tbqyj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class ResNet(nn.Module):\n",
        "#    def __init__(self, block, num_blocks, num_classes=10):\n",
        "#        super(ResNet, self).__init__()\n",
        "#        self.in_planes = 64\n",
        "#        self.activation = F.relu\n",
        "#        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "#                               stride=1, padding=1, bias=False)\n",
        "#        self.bn1 = nn.BatchNorm2d(64)\n",
        "#        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "#        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "#        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "#        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "#        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "#    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "#        strides = [stride] + [1]*(num_blocks-1)\n",
        "#        layers = []\n",
        "#        for stride in strides:\n",
        "#            layers.append(block(self.in_planes, planes, self.activation, stride))\n",
        "#            self.in_planes = planes * block.expansion\n",
        "#        return nn.Sequential(*layers)\n",
        "\n",
        "#    def forward(self, x):\n",
        "#        out = self.activation(self.bn1(self.conv1(x)))\n",
        "#        out = self.layer1(out)\n",
        "#        out = self.layer2(out)\n",
        "#        out = self.layer3(out)\n",
        "#        out = self.layer4(out)\n",
        "#        out = F.avg_pool2d(out, 4)\n",
        "#        out = out.view(out.size(0), -1)\n",
        "#        out = self.linear(out)\n",
        "#        return out\n"
      ],
      "metadata": {
        "id": "uGIg1q5hbwq6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def ResNet18():\n",
        "#    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "#def ResNet34():\n",
        "#    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "#def ResNet50():\n",
        "#    return ResNet(Bottleneck, [3, 4, 6, 3])"
      ],
      "metadata": {
        "id": "eUTBIQf2by4m"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n"
      ],
      "metadata": {
        "id": "fuyhwC0Ko0c4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### WideResNet\n",
        "\n",
        "class BasicBlockW(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, drop_rate=0.0):\n",
        "        super(BasicBlockW, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = drop_rate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                                                                padding=0, bias=False) or None\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "        else:\n",
        "            out = self.relu1(self.bn1(x))\n",
        "\n",
        "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
        "\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(nb_layers):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth=28, num_classes=10, widen_factor=10, drop_rate=0.0):\n",
        "        super(WideResNet, self).__init__()\n",
        "        n_channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
        "        assert ((depth - 4) % 6 == 0)\n",
        "        n = int((depth - 4) / 6)\n",
        "        block = BasicBlockW\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, n_channels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "\n",
        "        self.block1 = NetworkBlock(n, n_channels[0], n_channels[1], block, 1, drop_rate)\n",
        "\n",
        "        self.block2 = NetworkBlock(n, n_channels[1], n_channels[2], block, 2, drop_rate)\n",
        "\n",
        "        self.block3 = NetworkBlock(n, n_channels[2], n_channels[3], block, 2, drop_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(n_channels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(n_channels[3], num_classes)\n",
        "        self.nChannels = n_channels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "eMnobAkbcpyH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataloader, val_dataloader = train_val_dataloader()\n",
        "test_loader = test_dataloader()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b2a082ng909",
        "outputId": "95bb5ec9-c5e5-499c-a320-6a73ee1f28cc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50()\n",
        "model.to(device)\n",
        "model.device = device\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "cb = CallBack(evaluate)\n",
        "train_full(model, train_dataloader, val_dataloader, loss_fn, optimizer, n_epochs=30, callback=cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "140f36be62884c6599ebbeb158c510fb",
            "deb6e2113cc447b086689fcbdad52c04",
            "b82a70b6df324aeaab2a9eb75bf85644",
            "200602909c07477cbcb532a0d65d5432",
            "334914dcb0c9465fa5d60661731228d4",
            "42960e386be646aebc002e0568c76564",
            "8b7e55b7f8fc42d589f1e65ab0cb5595",
            "cfebb3f379e44337a62adbc059dbe9ee",
            "ab493f44ff394bebb85e98de872d0f0d",
            "de9a1672a6fd47049e807687982874b9",
            "3caddfc99f464c39ae5cab28c6afb89a"
          ]
        },
        "id": "CYibWIl3fk3V",
        "outputId": "a0d3278b-d019-481a-d379-a8287955aeea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "140f36be62884c6599ebbeb158c510fb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = evaluate(model, test_loader, loss_fn)\n",
        "print(f'ResNet50, test loss: {loss}')\n",
        "print(f'ResNet50, test accuracy: {acc}')"
      ],
      "metadata": {
        "id": "YiS4s5ZJgkm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "plt.title('ResNet50, train and validation loss')\n",
        "plt.xlabel('Number of epoch')\n",
        "plt.ylabel('Loss')\n",
        "epochs = np.arange(30) + 1\n",
        "plt.plot(epochs, cb.train_losses, label='Train')\n",
        "plt.plot(epochs, cb.train_w_losses, label='Train weighted')\n",
        "plt.plot(epochs, cb.val_losses, label='Validation')\n",
        "plt.legend()\n",
        "plt.grid(True)\n"
      ],
      "metadata": {
        "id": "67yEgznbgqG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best loss on train: {np.min(cb.train_losses)}, on {np.argmin(cb.train_losses) + 1} epoch')\n",
        "print(f'Best weighted loss on train: {np.min(cb.train_w_losses)}, on {np.argmin(cb.train_w_losses) + 1} epoch')\n",
        "print(f'Best loss on validation: {np.min(cb.val_losses)}, on {np.argmin(cb.val_losses) + 1} epoch')"
      ],
      "metadata": {
        "id": "pXMUyITWgv1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "plt.title('ResNet50, train and validation accuracy')\n",
        "plt.xlabel('Number of epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "epochs = np.arange(30) + 1\n",
        "plt.plot(epochs, cb.train_accs, label='Train')\n",
        "plt.plot(epochs, cb.val_accs, label='Validation')\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "RtqgLzixgwki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best accuracy on train: {np.max(cb.train_accs)}, on {np.argmax(cb.train_accs) + 1} epoch')\n",
        "print(f'Best accuracy on validation: {np.max(cb.val_accs)}, on {np.argmax(cb.val_accs) + 1} epoch')"
      ],
      "metadata": {
        "id": "qBwdbovOgyK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}