{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models import ResNet50\n",
    "from src.utils.common import UnCallBack\n",
    "from src.utils.evaluate import makeEval\n",
    "from src.utils.data_loaders import train_val_dataloader, test_dataloader, train_dataloader\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonArguments( test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = ResNet50()\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 )\n",
    "\n",
    "    eval_callback = makeEval(test_loader, loss_fn, device)\n",
    "\n",
    "    return {\"model\":model, \"optimizer\":optimizer, \"loss_fn\":loss_fn, \"eval\":eval_callback, \"device\":device}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport src.utils.common\n",
    "%aimport src.utils.evaluate\n",
    "%aimport src.train_schaul\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper-bound and/or Loss\n",
    "\n",
    "To use Upper-bound method use use_loss_estimation = False, \\\n",
    "for Loss use use_loss_estimation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_importance_sampling import  train_full_upper_bound\n",
    "\n",
    "def upperBoundOrLoss(train_loader, test_loader, n_epochs = 50, use_loss_estimation = False):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model = ResNet50()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 )\n",
    "\n",
    "    callback = UnCallBack( info_list = ['train_loss', 'train_acc', 'train_w_loss', 'val_loss', 'val_acc', 'train_uniform_cnt'])\n",
    "\n",
    "    eval_callback = makeEval(test_loader, loss_fn, device)\n",
    "\n",
    "    train_full_upper_bound( model, \n",
    "                train_loader, \n",
    "                loss_fn, \n",
    "                optimizer, \n",
    "                n_epochs = n_epochs, \n",
    "                eval = eval_callback, \n",
    "                callback = callback, \n",
    "                presample = 3, \n",
    "                tau_th = None,\n",
    "                use_loss_estimation = use_loss_estimation,\n",
    "                second_approach = True,\n",
    "                device= device)\n",
    "\n",
    "    if use_loss_estimation:\n",
    "        callback.save(\"callbacks/loss\")\n",
    "    else:\n",
    "        callback.save(\"callbacks/upper_bound\")\n",
    "\n",
    "    return callback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_rho_loss import train_full_rho_loss\n",
    "def rhoLoss(train_loader, test_loader, n_epochs = 50, train_irr_loader = None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = ResNet50()\n",
    "    model.to(device)\n",
    "\n",
    "    model_irr = ResNet50()\n",
    "    model_irr.to(device)\n",
    "\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 )\n",
    "    optimizer_irr = torch.optim.Adam(model_irr.parameters(), lr = 1e-3 )\n",
    "\n",
    "    callback = UnCallBack( info_list = ['train_loss', 'train_acc', 'train_w_loss', 'val_loss', 'val_acc', 'train_uniform_cnt'])\n",
    "\n",
    "    eval_callback = makeEval(test_loader, loss_fn, device)\n",
    "\n",
    "    train_full_rho_loss(model, \n",
    "            model_irr,\n",
    "            train_loader, \n",
    "            train_irr_loader,\n",
    "            loss_fn, \n",
    "            optimizer, \n",
    "            optimizer_irr,\n",
    "            n_epochs=n_epochs, \n",
    "            eval=eval_callback, \n",
    "            callback=callback, \n",
    "            presample=3, \n",
    "            tau_th = None)\n",
    "\n",
    "    callback.save(\"rho_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schaul training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1\n",
    "from src.train_schaul import train_full_schaul, train_full_schaul2\n",
    "\n",
    "\n",
    "def schaul(train_loader, test_loader, n_epochs = 50):\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = ResNet50()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 )\n",
    "\n",
    "    callback = UnCallBack( info_list = ['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "\n",
    "    eval_callback = makeEval(test_loader, loss_fn, device)\n",
    "\n",
    "    train_full_schaul(model, \n",
    "                    train_loader, \n",
    "                    loss_fn, \n",
    "                    optimizer, \n",
    "                    n_epochs = n_epochs, \n",
    "                    eval = eval_callback, \n",
    "                    callback = callback, \n",
    "                    device = device)\n",
    "\n",
    "    callback.save(\"callbacks/schaul\")\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loshchilov training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_loshchilov import train_full_loshchilov\n",
    "\n",
    "def loshchilov(train_loader, test_loader, n_epochs = 50):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = ResNet50()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 )\n",
    "\n",
    "    callback = UnCallBack( info_list = ['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "    eval_callback = makeEval(test_loader, loss_fn, device)\n",
    "\n",
    "    train_full_loshchilov(model, \n",
    "                        train_loader, \n",
    "                        loss_fn, \n",
    "                        optimizer, \n",
    "                        n_epochs=n_epochs, \n",
    "                        eval = eval_callback, \n",
    "                        callback=callback, \n",
    "                        device = device)\n",
    "\n",
    "    callback.save(\"callbacks/loshchilov\")\n",
    "\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "%autoreload 1\n",
    "callback = UnCallBack( info_list = ['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "callback.save(\"callbacks/loshchilov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataloader\u001b[49m(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m      5\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m test_dataloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n\u001b[0;32m      7\u001b[0m callback_upper_bound \u001b[38;5;241m=\u001b[39m upperBoundOrLoss(train_loader, test_loader, n_epochs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "%autoreload 1\n",
    "n_epochs = 2\n",
    "\n",
    "\n",
    "train_loader = train_dataloader(batch_size=300)\n",
    "test_loader = test_dataloader(batch_size=120)\n",
    "\n",
    "callback_upper_bound = upperBoundOrLoss(train_loader, test_loader, n_epochs)\n",
    "callback_loss = upperBoundOrLoss(train_loader, test_loader, n_epochs, use_loss_estimation=True)\n",
    "\n",
    "\n",
    "\n",
    "train_irr_loader  = train_dataloader(batch_size=120, subset=0.25)#128*3\n",
    "train_loader, test_loader = train_val_dataloader(batch_size=120, index=True)\n",
    "test_loader = test_dataloader(batch_size=120)\n",
    "\n",
    "\n",
    "#train_loader = train_dataloader(batch_size=80)\n",
    "#test_loader = test_dataloader(batch_size=80)\n",
    "train_loader, test_loader = train_val_dataloader(batch_size=120)\n",
    "schaul_callback = schaul(train_loader, test_loader, n_epochs)\n",
    "\n",
    "\n",
    "train_loader = train_dataloader(batch_size=64)\n",
    "test_loader = test_dataloader(batch_size=64)\n",
    "loshchilov_callback = loshchilov(train_loader, test_loader, n_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
